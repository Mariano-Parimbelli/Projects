{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db7f8249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "from nltk.stem import SnowballStemmer\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import csv\n",
    "import re \n",
    "import string\n",
    "import preprocessor as p\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score \n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "import spacy\n",
    "from sklearn import *\n",
    "nlp=spacy.load('es_core_news_lg')\n",
    "spanish_stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "CONSUMER_KEY='sj7r6f0zF37UB35yiFUWhG3mw'\n",
    "CONSUMER_SECRET='kciblvx1oHsKJn0ggPxuswSJBeMgeU1vSFiqTmqGgytwHX2G4H'\n",
    "ACCESS_KEY='1439327344536264711-GegKaB1npGPB4vubPVPzZHjaQywGBl'\n",
    "ACCESS_SECRET='RsSRxRUOClFgh9RqWX3kxq3HV9FiyDVE4YTyGdvYwvN1I'\n",
    "# authentication\n",
    "\"\"\"auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\"\"\"\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34cef442",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER='AAAAAAAAAAAAAAAAAAAAADtbdgEAAAAA3jZdkB0mA%2BzRvmohygx%2BQAYgF6g%3DIRBwQuUHUatX216RMyG7AdjxLZWHTGIjcaoJ3nzhl0HDwYWmTB'     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c896f34",
   "metadata": {},
   "source": [
    "## Descarga de nuevos Tweets para hacer la clasificacion de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ef76495",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "client = tweepy.Client(bearer_token=BEARER, consumer_key=CONSUMER_KEY, consumer_secret=CONSUMER_SECRET,\n",
    "                       access_token=ACCESS_KEY, access_token_secret=ACCESS_SECRET,return_type = requests.Response,  wait_on_rate_limit=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da28c1f3",
   "metadata": {
    "code_folding": [
     0,
     1
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def mandar_tweet():\n",
    "    for i in range(2):\n",
    "        query = \"Elon Musk  lang:es -is:retweet\"\n",
    "\n",
    "\n",
    "        # your start and end time for fetching tweets\n",
    "\n",
    "\n",
    "        # get tweets from the API\n",
    "        tweets = client.search_recent_tweets(query=query,\n",
    "                                             tweet_fields = [\"created_at\", \"text\", \"source\"],\n",
    "                                             user_fields = [\"name\", \"username\", \"description\"],\n",
    "                                             max_results = 100,\n",
    "                                             expansions='author_id'\n",
    "                                             )\n",
    "\n",
    "\n",
    "        tweets_dict = tweets.json() \n",
    "\n",
    "        # Extract \"data\" value from dictionary\n",
    "        tweets_data = tweets_dict['data'] \n",
    "\n",
    "        # Transform to pandas Dataframe\n",
    "        df = pd.json_normalize(tweets_data) \n",
    "\n",
    "        normalized_places = pd.json_normalize(tweets_dict['includes']['users']).set_index('id')\n",
    "        df2=pd.merge(normalized_places,df,left_on='id',right_on='author_id')\n",
    "\n",
    "        df2=df2.drop([\"description\",\"author_id\",\"id\",\"source\",\"name\"],axis=1)  \n",
    "\n",
    "        df2[\"text\"][5]\n",
    "        df2\n",
    "\n",
    "        df2[\"created_at\"]=\"20220616\"\n",
    "\n",
    "\n",
    "            #saco links\n",
    "        df2[\"text\"] = df2[\"text\"].replace({r'(http|https|\\n\\nhttps|\\nhttps):\\/\\/([^\\/\\r\\n]+)(\\/[^\\r\\n]*)?':' '}, regex=True)\n",
    "        df2[\"text\"] = df2[\"text\"].replace({r'\\W+':' '}, regex=True)\n",
    "\n",
    "\n",
    "        df3=pd.DataFrame()\n",
    "        df3.insert(0, 'fecha', df2.created_at)\n",
    "        df3.insert(1, 'texto', df2.text)\n",
    "        df3.insert(2, 'usuario', df2.username)\n",
    "\n",
    "\n",
    "        # Converting first column to Series\n",
    "        fecha = df3.iloc[:,0]\n",
    "        texto = df3.iloc[:,1]\n",
    "        usuario = df3.iloc[:,2]\n",
    "        url = 'https://rutbmzlxuu8vw3w-db20220601185600.adb.sa-saopaulo-1.oraclecloudapps.com/ords/pln/pln/registrar'\n",
    "\n",
    "    for i in range(len(fecha)):\n",
    "        texto[i]=texto[i].strip()\n",
    "        x = requests.post(url,headers = {\"fecha\": str(fecha[i]),\"texto\":str(texto[i]),\"usuario\":str(usuario[i])})\n",
    "        print(x.text)\n",
    "    print(\"__________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dde55ce",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_clasificador():\n",
    "    global comparar\n",
    "    global df3\n",
    "    for i in range(1):\n",
    "        query = \"Elon Musk  lang:es -is:retweet\"\n",
    "\n",
    "\n",
    "        # your start and end time for fetching tweets\n",
    "\n",
    "\n",
    "        # get tweets from the API\n",
    "        tweets = client.search_recent_tweets(query=query,\n",
    "                                             tweet_fields = [\"created_at\", \"text\", \"source\"],\n",
    "                                             user_fields = [\"name\", \"username\", \"description\"],\n",
    "                                             max_results = 10,\n",
    "                                             expansions='author_id'\n",
    "                                             )\n",
    "\n",
    "\n",
    "        tweets_dict = tweets.json() \n",
    "\n",
    "        # Extract \"data\" value from dictionary\n",
    "        tweets_data = tweets_dict['data'] \n",
    "\n",
    "        # Transform to pandas Dataframe\n",
    "        df = pd.json_normalize(tweets_data) \n",
    "\n",
    "        normalized_places = pd.json_normalize(tweets_dict['includes']['users']).set_index('id')\n",
    "        df2=pd.merge(normalized_places,df,left_on='id',right_on='author_id')\n",
    "\n",
    "        df2=df2.drop([\"description\",\"author_id\",\"id\",\"source\",\"name\"],axis=1)  \n",
    "\n",
    "\n",
    "            #saco links\n",
    "        df2[\"text\"] = df2[\"text\"].replace({r'(http|https|\\n\\nhttps|\\nhttps):\\/\\/([^\\/\\r\\n]+)(\\/[^\\r\\n]*)?':' '}, regex=True)\n",
    "        df2[\"text\"] = df2[\"text\"].replace({r'\\W+':' '}, regex=True)\n",
    "        df2[\"text\"] = df2[\"text\"].replace({r'[,.:?’_¡—“¿%;!/`''©@)°C(\\\"\\n]':' '}, regex=True)\n",
    "        df2[\"text\"] = df2[\"text\"].replace({r'[0-9]':' '}, regex=True)\n",
    "        \n",
    "\n",
    "        df3=pd.DataFrame()\n",
    " \n",
    "        df3.insert(0, 'Tweet', df2.text)\n",
    "        comparar=df3.copy()\n",
    "    return(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba3024d",
   "metadata": {},
   "source": [
    "## Pipeline de pre procesamiento de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8255dc15",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    " def stopWords(corpus):\n",
    "    global oraciones\n",
    "    global oraciones_filtradas\n",
    "    f = open('StopWords.txt', 'r')\n",
    "    stopwords = f.read().split('\\n')\n",
    "    f.close()\n",
    "    \" \".join(stopwords)\n",
    "    oraciones=list(corpus)\n",
    "\n",
    "    oraciones_filtradas = [\" \".join([\n",
    "                              palabra for palabra in oracion.split()\n",
    "                              if palabra not in stopwords])\n",
    "                              for oracion in oraciones]\n",
    "stopWords(df3[\"Tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17465ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spanish_stemmer = SnowballStemmer('spanish')\n",
    "oraciones_filtradas_lematizadas=[]\n",
    "for oracion in oraciones_filtradas:\n",
    "    oracion_lematizada = []\n",
    "    for palabra in oracion.split():\n",
    "        doc=nlp(palabra)\n",
    "        oracion_lematizada.append(doc[0].lemma_)\n",
    "    oraciones_filtradas_lematizadas.append(\" \".join(oracion_lematizada))\n",
    "    \n",
    "\n",
    "oraciones_filtradas_lematizadas_stemm=[]\n",
    "\n",
    "for oracion in oraciones_filtradas_lematizadas:\n",
    "    oracion_stemm = []\n",
    "    for palabra in oracion.split():\n",
    "        oracion_stemm.append(spanish_stemmer.stem(palabra))\n",
    "    oraciones_filtradas_lematizadas_stemm.append(\" \".join(oracion_stemm))\n",
    "    \n",
    "df3['Tweet'] = oraciones_filtradas_lematizadas_stemm\n",
    "df3 = df3.drop_duplicates().reset_index(drop=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4002d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df3.replace('', np.nan).dropna()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b40bf4ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the spy who lov yo bond moor mas floj uno vill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jesusrener record ciert cre tesl fundador este...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algun vez hab vist escuch biograf monstru nego...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>omo elon musk hab hund todav mas twitt poz perd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sinline mx seis millon bot exceptu asquer fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sinline mx por compr elon musk twitt gent com ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lueg vari mes incertidumbr sobr compr twitt pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a men ver bail asi hij elon musk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gulfstream g asi dentr nuev avion elon musk lu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet\n",
       "0  the spy who lov yo bond moor mas floj uno vill...\n",
       "1  jesusrener record ciert cre tesl fundador este...\n",
       "2  algun vez hab vist escuch biograf monstru nego...\n",
       "3    omo elon musk hab hund todav mas twitt poz perd\n",
       "4  sinline mx seis millon bot exceptu asquer fami...\n",
       "5  sinline mx por compr elon musk twitt gent com ...\n",
       "6  lueg vari mes incertidumbr sobr compr twitt pa...\n",
       "7                   a men ver bail asi hij elon musk\n",
       "8  gulfstream g asi dentr nuev avion elon musk lu..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset listo\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea018a48",
   "metadata": {},
   "source": [
    "## Clasificacion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf6c7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "global result\n",
    "global probabilidad\n",
    "corpus=df3[\"Tweet\"]\n",
    "loaded_vec = CountVectorizer(vocabulary=pickle.load(open(\"cuerpo.pkl\", \"rb\"))) \n",
    "new_input=loaded_vec.transform(corpus)\n",
    "new_input=pd.DataFrame(new_input.toarray()) \n",
    "\n",
    "\n",
    "clf_input=pickle.load(open(\"prediccion.sav\", \"rb\"))\n",
    "predict_input=clf_input.predict(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "011399f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input=pd.DataFrame(predict_input)\n",
    "predict_input.columns=[\"clase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c737c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input['clase']= predict_input['clase'].replace(1,\"Positivo\")\n",
    "predict_input['clase']= predict_input['clase'].replace(0,\"Negativo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "630a6f52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      clase\n",
       "0  Negativo\n",
       "1  Negativo\n",
       "2  Positivo\n",
       "3  Negativo\n",
       "4  Negativo\n",
       "5  Positivo\n",
       "6  Positivo\n",
       "7  Positivo\n",
       "8  Negativo"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " predict_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed032381",
   "metadata": {},
   "outputs": [],
   "source": [
    " predict_input.insert(1, 'Tweet', comparar.Tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2330033b",
   "metadata": {},
   "source": [
    "## RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a2ed82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clase</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negativo</td>\n",
       "      <td>The Spy Who Loved Me es el Bond de Moore más ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negativo</td>\n",
       "      <td>jesusrenero Recordemos por cierto que no creó...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>Alguna vez has visto o escuchado la biografía...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negativo</td>\n",
       "      <td>ómo Elon Musk ha hundido todavía más a Twitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negativo</td>\n",
       "      <td>SinLinea Mx Seis millones de bots Exceptuando...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>SinLinea Mx Por eso no lo compro Elon Musk a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>Luego de varios meses de incertidumbre sobre l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Positivo</td>\n",
       "      <td>A menos que la vea bailando asi con un hijo de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Negativo</td>\n",
       "      <td>Gulfstream G    así es por dentro el nuevo avi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      clase                                              Tweet\n",
       "0  Negativo   The Spy Who Loved Me es el Bond de Moore más ...\n",
       "1  Negativo   jesusrenero Recordemos por cierto que no creó...\n",
       "2  Positivo   Alguna vez has visto o escuchado la biografía...\n",
       "3  Negativo   ómo Elon Musk ha hundido todavía más a Twitte...\n",
       "4  Negativo   SinLinea Mx Seis millones de bots Exceptuando...\n",
       "5  Positivo   SinLinea Mx Por eso no lo compro Elon Musk a ...\n",
       "6  Positivo  Luego de varios meses de incertidumbre sobre l...\n",
       "7  Positivo  A menos que la vea bailando asi con un hijo de...\n",
       "8  Negativo  Gulfstream G    así es por dentro el nuevo avi..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "display(predict_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18c07934",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input.to_csv(\"prediccion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d144fdbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
